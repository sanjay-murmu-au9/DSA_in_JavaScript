# What is data Structures?
Ans:- Data structures allow you to manage data, retrive data, delete data and so on.

Example:- Arrays, Objects, Maps, Sets;
 [1,2,3] || {name:'sanjay',age:31} || new Map() map.set('a','b')  || new Set() set.add(1)



# Arrays - A Closer Look;
	[1,3,6,2]
	1. Insertion order is kept/memorize;
	2. Element can be access via index;
	3. Elemeny (= you can use the for-of-loop)
	4. Size (length) adjusts dynamically;
	5. Deletion and findling elements can be require "extra work".

=====================xxxx===========================
# Sets  - A Closer Look;
new Set()
Set.add('pizza')
Set.add('burger')
Set.add('pizza') // not allowed;

1. Insertion order in not stored/memorized.
2. Element access and extration via method
3. Iterable(= you can use the for-of-loop)
4. Size (length) adjusts dynamically;
5. Duplicate values are not allowed(i.e Unique value only)
6. Deletion and finding elements is trivial and fast. 

=================XXXXXXXXX=====================
Arrays Vs Sets;

# Arrays
	1. You can always use arrays.
	2. Must-use if order matters and / or 
	duplicate are wanted;


# Sets;
	1. Only usable if order does not matter
		and you can only need unique values

	2. Can simplify data access (e.g finding, deletion) compared to arrays.


=================XXXXXXXXX=====================

# Objects - A Closer Look

	{
		name:'Max',
		age:31,
		greet(){console.log('Hi,I am'+ this.name)}
	}

 1. Unordered key-value pairs of data;
 2. ELements access via key (property name)
 3. Not iterable (only with for-in)
 4. Keys are unique, values are not
 5. keys have to be strings,numbers,symbols.
 6. Can store data & "functionality"(methods)	


=================XXXXXXXXX=====================
Maps - A CLoser Look;
	new Map()
	map.set('name','Max')
	map.set('name','Max')
	map.set(true,true) // Boolean key

	1. Ordered key-value pairs of data.
	2. Element access via key;
	3. Iterable(= you can use the for-of-loop)
	4. keys are unique, values are not.
	5. keys can be anything (include reference values like arrays)
	6. Pure data storage, optimized for data access.



=================XXXXXXXXX=====================
# Objects Vs Maps;

Objects
	1. Very versatile construct and data storage in javascript;
	2. Must- use if you want to add extra functionality.

Maps;-
	1. Focused on data storage and access.
	2. Can simplify and imporve data access compared to objects.


=================XXXXXXXXX=====================
WeakSet & WeakMap:-
	1. Variations of Set and Map --> 
	Values and keys are only "weakly referenced" -->
	Garbage collection can delete values and keys if not used anywhere else in the app.

=================XXXXXXXXX=====================
 A Custom Data Structure: "Linked List";
#Linked List;
	1. Every element knows about the next element BUT not back one(PREV ONE);
	2. This allows for efficient re-sizing and insertion at start and end of the list.
Example:-
	[5 -->(next) 'hi' -->(next) 8 ---> 11(next) --> null]



# Why would you want a "Linked List"?
 Ans:- Historically (in other programming languages), the main reason was memory management: 
	You didn't have to specify (occupy) the size in advance.
* Insertion at the start and end of the list is very efficient, more eficient then the array.

Nowadays, Javascript has dynamic arrays (dynamic re-sizing built in)and memory isn't really
	the primary issue in javascript apps.

# LinkedList can be useful if you do a lot of insertions at the beginning of the lists - 
	linked lists are faster then array at this.

# TIme COmplexity & Big O Notation;
funtion sumUp(n){
   let result = 0;
  for (let i=1; i<= n; i++){
     result+= i;
  }
  resturn result;
}  // --------------------> A bigger number leads to more loop iterations hence time
	increases in a linear way.

# Linear Time =  O(n);
# Constant Time = O(1);
# Quadratic TIme = O(n^2) // n power 2
# Cubic TIme = O(n^3)


# Linked List Time Complexity & Arrays;
				Linked List			Arrays;
Element Access		 O(n)				O(1); --> With index

Insertion at End		With tail: O(1)		O(1)
				without tail: O(n)	

Insertion at Beginning	O(1)				O(n); // need to shift all the other element;

Insertion in Middle	Search time + O(1)	O(n);

Search Elements 		O(n)				O(n)


===================XXX==========================;
# What are List & Table Structures?
2. Stacks & Queue;
3. Hash Table;

# What are List & Table Structures?
	# Lists:- (e.g: Shop)
		1. Collections of Values;
		e.g. Arrays,Sets, LinkedLists;
		Great for storing values that are 
		retrieved by position (via index or search) Also great for loops.

	# Tables;
		1. Collections of key-Values Pairs
			e.g. Objects, Maps
		# Great for storing values that are retrieved by key Not primarily focused on loops.

===================XXXX=========================
# Stack;
	LIFO: Last In, First Out;

	# New Item are always added ('pushed') on top of the stack
	# Items are always removed ("Popped") from top of the stack.

# Stack Time Complexity & Arrays:-

				stacks					Arrays
Element Access		0(1)						O(1) //bcs access them by index
			   	But limited to "top element"

Insertion at End		O(1)						O(1)

Insertion at Begining	O(n) With "Data Loss"			O(n)

Insertion in Middle	O(n) With "Data Loss"			O(n)

Search Elements		O(n) With "Data Loss"			O(n)


===================XXXX=========================
Queue;-[FIFO: first in,first Out] A Simpified array.(we work on both end)
#  We add[pushed] new items always at the top of the stack (begining) or removed ["popped"] items from top of the stack.
	1. We can "Enqueue" in the arr or "Dequeue" from the arr.



Queue Time Complexity & Arrays;

						Queues							Arrays
			
Element Access			O(1) "but limited tofirst element"	O(1)

Insertion atEnd			O(n) With data loss				O(1)
Inserion at Beginning	O(1)							O(n);
Insertion in Middle		O(n) with data loss				O(n);
Search Elements			O(n) With Data loss				O(n)

==================XXXX=============================
# Introducing Hash Tables;
: THe exisiting Javascript "object" is implemented as a Hash Table!

Input			Hashing Function					Hash Table
Key:'name'		Converts key to an index		index			Value
Value: 'Max'('name'--> 1 index)
 									0			31
									1			'Max'
									2			null
									...			...



==================XXXX=============================
# Module Content;
	# Tree Structures
		1. Adding Depth  
1. what are Tree Strucutres?
2. Binary Search Tree & AVL Tree
3. Tries

#Important Terminology(1/2)
	1.node/vertex ---> A Structure that contains a value;
	2.Edge:- A connection between exectly two nodes;
	3.Root Node:- The top-most node in the tree.
	4.Sub Tree:- A Nested tree (i.e. sub tree root node is NOT main tree node)
	5.Leaf:- A node without any child nodes (i.e. without a sub tree)
	6.Path:- A sequence of nodes and edges that connects two nodes.
	7.Distance:- The number of edges between two nodes.
	8.Parent/Child: Two directly connected nodes, parent node is "above" child node.
	9.Ancestor/Descendant: Two nodes that are connected by multiple parent-child paths.
	10.sibling:- Two adjacent nodes with the same parent.

#Important Terminology(2/2)
	1. Degree:-	The number of child nodes of a given node.(i.e.root node has 2 degree)
	2. Level:-	The distace b/w a node and the root node;
	3. Depth:-	The maximum level in a tree.
	4. Breadth:- The number of leaves in a tree.
	5. Size:-	 The total number of nodes in a tree.

# Tree Time Complexity
				Tree				Array
Access/Search		Worst Case: O(n)		O(1) (with Index)
								O(n) (search)

Insertion			Worst Case: O(n)		O(1) at end
								O(n) at beginning

Removal			Worst Case: O(n)		O(1) at end
								O(n) at the beginning

## Traversing Tree;
	1. Depth-First:-	Dig into the tree first and explore sibling tress step by step.

	2. Breadth-First:- Evaluate all the sibling values first before you dig into the tree in depth.
	
==================Binary Search Trees==========================
# Binary Search Trees;
# A Tree for Sorted Data (Works with any value types!) 
# Every Node has at most 2 child nodes
# Left child Nodes has Smaller node 
# Right Child Nodes has Bigger node.

Example:-
	10(rootNodes)
# LeftNOde 5 
	has two child smaller then RightNode && left node is smaller then parentnode "5" > 2,  6 

# RightNode 14
	has child but but bigger then ParentsNode 24;

# Binary Search Tree Complexity;

				# BinarySearchTree			#Array
Access/Search 		Worst Case: O(n)			  	O(1) With Index
				Average Case: O(log n)			O(n) (search)

Insertion			Worst Case: O(n)			  	O(1) (at end)
				Average Case: O(log n)			O(n) (at beginning)
	
Removal			Worst Case: O(n)			  	O(1) at end
				Average Case: O(log n)			O(n) (at beginning)


# Fixing the BST Worst Case via Balancing;
	: Subtrees should have a depth that is equal or differs by at most 1.
			10(rootNode)
2 (Left)						5(right)

THis is called  "AVL Tree". :- Georgy Adelson -Velsky Evgenii Landis.

				10
	2								5 ---> Depth 1;
1   ---> this has depth 2

This is an AVL tree because subtree depth only differs by 1.

					10
			5
		2

* Worst Case: Only are "line of Nodes" & Looking for "2" --> left depth is 2, right depth 0, hence it is unbalance.

====XX===
					10

		2						5
*Subtrees should have a depth that is equal or differs by at most 1.

#Balancing AVL Trees;
	#Left Rotation
	1				2
	   2			 1		3

		3 ---->		

# Riht Rotation
		3  ------> 		2
	    2			   1	     3;
	  1

#  Left-Right Rotation
	3    =====>  3 ===>	   2
    1			2  		 1    3
	  2	     1	
	
# Right-left Rotation
  1   ====>     1 	===>     2
    3  		2		1	3
  2 			   3

# Balance Factors
 * Balance Factor: Difference b/w subtree depths (left - right)


==========Tries=======
Tries:-A tries is a tree with root node, but with the root node that always has an empty value.
root node holds no values.

Time Complexity & Hash Table Comparison;
Operation		Tries			Hash Tables
  insert		O(n)			O(n) (with hash collisions)
  Find		O(n)			O(n) (with hash collisions)
  Delete		O(n)			O(n) (with hash collisions)

Spece Complexity	O(n*k)		O(n)

==========================XXX=======================
# What are Priority Queues?
# What are Heaps?

#Priority Queues:-Prioritize item in a queue, instead of processing them one after 
	another( with equal priority)

# LinkedList Priority Queue - Time Complexity;
Insert ---> O(n) || O(1) if first item/ high priority);

Process -----------> O(1)
 
==================Heaps=============================
# (Min) Heaps are trees where the parent node values are smaller or equal than the child
  node the child node values (for a "max heap", it's the other way around).

Example:-						   3
						5			20
					21		9	25		22


else								250
							197			85
						102		12	40		15

#How to find parent index formula;
	const heap = [250,197,85,101,12,40,15];
	heap[6] --> 15
* formula that gives us the index of the parent element.
	Math.floor((6+1)/2)-1;  --->2
	Math.floor((5+1)/2)-1;  --->2


============Graph=============GRAPH===============
# What are Graph Structures?:-
	Ans:- > Graphs is a kind of tree but breaking all the tree rules.
	in a graph we can have a connections via vertex/nodes via edged to multiple other nodes
	so we don't just have a parent-child relation,node on the same level can be connected to each other
	and hence loops, cycles are possible.
# Two kind of Graphs:-
	1. Directed Graph :- Edge between nodes are unidirectional. a--->b --->c, c--->a;
	2. Undirected Graph:- Edges b/w nodes are bi-directional, nodes can point back at other nodes.


# Representing a Graph in Code;
			    Two approaches
	Adjacency Matrix:-				Adjacency List
	 
# Adjacency Matrix
	ex 1---->3 ---->2, 1---->2
	
			1	2	3
		1	0	1	1
		2	0	0	0
		3	0	1	0 ---> this is adjacency matrix;

#In the console;-
 const adjMatrix = [
    [0,1,1],
    [0,0,0],
    [0,1,0]
];
adjMatrix[1][2] --> 0;
adjMatrix[0] ---> [0, 1, 1];
adjMatrix[0].filter(edge=>edge>0) --> (3) [0, 1, 1];

# Adjacency List ========>
	EX:- 1---->2, 1--->3, 3---->2;
	
	1   2   3
	2
	3   2

  const adjList = {
    1: [2,3],
    2: [],
    3: [2]
};
# adjList[1] --> (2) [2, 3];
# adjList[1].find(connectNode => connectNode ===2) ---> 2

# Diving into Graphs
# Adjacency Matrix Vs List;

# Time Complexity
			Adjacency Matrix		Adjacency List
Insert		O(n)				O(1);
Find Edge b/w
nodes			O(1)				O(n) or O(1) depends on implementation

Find all adjacent
 Nodes		O(n)				O(1)

#Space Complexity	:	
				O(n^2)		O(n+e) // no of nodes+edges


 
==================XXXX=============================
Welcome to the Course! 
What are "Data Structures"?
Arrays: Recap 
Sets: Recap 
Arrays vs Sets 
Objects: Recap 
Maps: Recap 
Objects vs Maps 
WeakSet and WeakMap 
Linked Lists (A First Custom Data Structures)
Starting with Linked Lists and "append" 
Outputting the Linked List
Prepend to Linked Lists 
Deleting Nodes 
"find" and "insertAfter" 
Linked Lists: Why and Time Complexity 
Linked Lists vs Arrays 
Module Introduction 
What are "Lists" and "Tables"? 
Built-in Lists and Tables 
Introducing "Stacks" 
Building a "Stack" Data Structure 
Considering a Linked List Stack 
Stacks with Linked Lists 
Stacks: Time Complexity 
Introducing Queues 
Building a Queue 
Linked Lists & Queues 
Queue Time Complexity 

Introducing Hash Tables 
Why we need Tables 
Building a Basic Hash Table 
Understanding Hash Collisions 
Solving Collisions with Chaining 
Solving Collisions with Open Addressing
Hash Tables: Time Complexity 
Hash Tables: Summary 

Module Introduction  ---> 38 video
What are "Trees"? 
Core Terminology 
An Example Tree 
A First Tree in Code 
A Better Filesystem Tree 
Removing Tree Nodes
Describing Our Tree 
Trees: Time Complexity 
Depth-first vs Breadth-first Search 
Implementing Depth-first Search 
Implementing Breadth-first Search 
Depth-first Search vs Breadth-first Search 

Introducing Binary Search Trees (BST) 
Adding Values to BST
Finding Values in BST 
Removing Leaf Nodes in BST 
Removing "One-Child" Nodes in BST 
Removing "Multi-Child" Nodes in BST 
BST Time Complexity 

Introducing AVL Trees 
Balancing Trees with Rotations 
Understanding Balance Factors 
Adding Depth and Balance Factors 
Finding the Right Rotation 
Implementing Left Rotation 
Implementing Right Rotation 
Implementing Left-Right Rotation
Implementing Right-Left Rotation 
Testing the AVL Tree 
AVL vs BST 

Introducing Tries 
Building a Trie 
Finding Nodes in a Trie 
Deleting Keys 
Tries: Time Complexity and Comparison to Hash Tables 

Module Introduction 
Understanding Priority Queues 
Building a Regular Queue 
Priority Queues & Time Complexity
Building a Basic Priority Queue 

Introducing Heaps 
Exploring the Heap Concept 
Building a Heap 
Processing Items 
A Heap-based Priority Queue
Heaps & Time Complexity 

Module Introduction 
Graphs: What and Why? 
Graphs with an Adjacency Matrix 
Using Adjacency Lists Instead 
Adjacency Lists vs Matrices 
Building a Graph Structure 
Adding Graph Methods 
Removing Nodes & Edges 
Using Sets in Graphs 
Summary 
Building a Social Network Graph


Social Media Marketting MASTERY | Learn Ads on 10+ platforms